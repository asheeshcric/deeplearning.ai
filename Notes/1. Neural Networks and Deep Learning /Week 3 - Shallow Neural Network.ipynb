{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is a Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/d79YnGD/Screenshot-from-2019-04-17-15-58-08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As shown in the above image, basically a neural network is a neuron (evaluated using Logistic Regression) repeated multiple times\n",
    "- In neural network notation, we don't count the input layer. So, the above shown neural network is a **\"2 layer NN\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/T0VYmkT/Screenshot-from-2019-04-17-16-06-35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Computing a Neural Network's Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The hidden layer has four neurons, so the output or activation from the hidden layer is a column vector with four single valued rows and is denoted by **a[1]** as it is the first layer of the network\n",
    "- In logistic regression, when input is X, a neuron computes the following two equations to get **z & a**:\n",
    "    - z = wx + b\n",
    "    - a = sigmoid(x)\n",
    "    - yhat = a (output of the neuron/layer)\n",
    "    - **Size and dimension of the layers depends on the number of neurons contained by the layer**\n",
    "\n",
    "![](https://i.ibb.co/0BQqjXc/Screenshot-from-2019-04-17-16-50-35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, for a neural network with hidden layers and multiple neurons, this is how the weights and biases are calculated\n",
    "- First the input layer (input values = X), is multiplied with the transpose of the first layer weights W[1].T, and passed through a sigmoid function to get the output from the first hidden layer (this implements Logistic Regression on the first layer)\n",
    "    - Same thing is repeated for the second layer where the output from the first acts as input to the second\n",
    "- From the output of the output layer, the cost function L is evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/q96kxQX/Screenshot-from-2019-04-17-16-53-42.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Final algorithm to implement the neural network for one example at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/ygS5JcW/Screenshot-from-2019-04-17-17-00-41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vectorizing across multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ibb.co/BCykzTw/Screenshot-from-2019-04-17-17-07-46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As shown in the above image, to train all the samples from a training set, we just stack each data point horizontally to create a matrix X\n",
    "    - X = [X1 X2 ... Xm]\n",
    "- Similarly, the Z vector is evaluated using the formula **z = w.T + b** for each column of the vector X to finally form matrix Z\n",
    "    - Z = [Z1 Z2 ... Zm]\n",
    "    - For each layer, there is a separate Z matrix\n",
    "    - e.g. Z[1], Z[2] represent the first and second layers of the network\n",
    "- The final output matrix of a layer A is the sigmoid of the matrix Z\n",
    "    - A = sigmoid(Z)\n",
    "    - This is the output of a layer and acts an input to the second layer\n",
    "    - If we go down vertically in a column of matrix A, it represents the activations from nodes of that hidden/output layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asheesh",
   "language": "python",
   "name": "asheesh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
